{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read csvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set directory path\n",
    "directoryPath = ('/Users/alia/Desktop/csvs/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob(directoryPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a df\n",
    "frame = pd.DataFrame()\n",
    "list_ = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read through csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for read in files:\n",
    "    reader = pd.read_csv(read,index_col=None, header=0, encoding = \"ISO-8859-1\")\n",
    "    patient = read[-7:-4]\n",
    "\n",
    "    #Extract what you need into dataframe\n",
    "    #\tNeed: pt ID\t\tErrorON\t\tErrorOFF\tstimON\t\tstimOFF\t\tstimdur\t\tstim latency\tError Lat. (this # will be negative, take only rows with - values)\n",
    "    reader['during_stim_pos'] = reader['stim_onset'].astype(float) - reader['s_onset'].astype(float)\n",
    "    reader['during_stim_neg'] = reader['s_onset'].astype(float) - reader['stim_offset'].astype(float)\n",
    "    reader['stim_effect'] = reader['s_offset'].astype(float) - reader['stim_onset'].astype(float)\n",
    "    reader['ptID'] = patient\n",
    "    frame = frame.append(reader)\n",
    "\n",
    "frame[\"during_stim_for_pos\"] = np.where(frame[\"during_stim_pos\"] > 0, 'yes', 'no')\n",
    "frame[\"during_stim_for_neg\"] = np.where(frame[\"during_stim_neg\"] < 0, 'yes', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export all data into a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output column names in new csv file with extracted info\n",
    "frame = frame.reindex_axis((\"ptID\", \"s_onset\", \"s_offset\", \"s_dur\", \"stim_onset\", \"stim_offset\", \"during_stim_pos\", \"during_stim_neg\", \"stim_effect\", \"error\",\"error2\",\"region\", \"during_stim_for_pos\", \"during_stim_for_neg\", \"stim_loc\", \"stim\", \"timePlot\"), axis=1)\n",
    "# frame = frame.dropna()\n",
    "#At the end of the for loop, write data to csv files (make sure to append)\n",
    "frame.to_csv('all_patients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export only trials with stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = frame[frame.stim == 'Y']\n",
    "frame = frame.reindex_axis((\"ptID\", \"s_onset\", \"s_offset\", \"s_dur\", \"stim_onset\", \"stim_offset\", \"during_stim_pos\", \"during_stim_neg\", \"stim_effect\", \"error\",\"Unnamed: 14\", \"during_stim_for_pos\", \"during_stim_for_neg\", \"stim_loc\", \"stim\", \"timePlot\", \"region\"), axis=1)\n",
    "\n",
    "frame.to_csv('stim_trials_only.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export everything without nopot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = frame[frame.timePlot != 'noplot']\n",
    "frame = frame.reindex_axis((\"ptID\", \"s_onset\", \"s_offset\", \"s_dur\", \"stim_onset\", \"stim_offset\", \"during_stim_pos\", \"during_stim_neg\", \"stim_effect\", \"error\",\"Unnamed: 14\", \"during_stim_for_pos\", \"during_stim_for_neg\", \"stim_loc\", \"stim\", \"timePlot\", \"region\"), axis=1)\n",
    "frame.to_csv('without_noplot_stim_only.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export only motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = frame[frame.error == 'motor']\n",
    "frame = frame.reindex_axis((\"ptID\", \"s_onset\", \"s_offset\", \"s_dur\", \"stim_onset\", \"stim_offset\", \"during_stim_pos\", \"during_stim_neg\", \"stim_effect\", \"error\",\"Unnamed: 14\", \"during_stim_for_pos\", \"during_stim_for_neg\", \"stim_loc\", \"stim\", \"timePlot\", \"region\"), axis=1)\n",
    "frame.to_csv('motor_only.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export only word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = frame[frame.error == 'word']\n",
    "frame = frame.reindex_axis((\"ptID\", \"s_onset\", \"s_offset\", \"s_dur\", \"stim_onset\", \"stim_offset\", \"during_stim_pos\", \"during_stim_neg\", \"stim_effect\", \"error\",\"Unnamed: 14\", \"during_stim_for_pos\", \"during_stim_for_neg\", \"stim_loc\", \"stim\", \"timePlot\", \"region\"), axis=1)\n",
    "\n",
    "frame.to_csv('word_only.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy and Error Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##reindex frame \n",
    "frame1 = pd.DataFrame()\n",
    "for i in frame:\n",
    "    a = frame[i].tolist()\n",
    "    frame1[i] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A_119', 'A_147', 'A_152', 'A_155', 'B_159', 'B_170', 'A_232', 'A_A63', 'B_A71']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "## find comorbid sites\n",
    "patient = np.unique(frame1['ptID'])\n",
    "# comorbid = pd.DataFrame()\n",
    "comorbid_sites = []\n",
    "co_index = []\n",
    "for p in patient:\n",
    "    motor = []\n",
    "    word = []\n",
    "    indx = np.where(frame1['ptID'] == p)\n",
    "    for i in indx[0]:\n",
    "        if frame1['error'][i] == 'motor':\n",
    "            if frame1['stim_loc'][i] in motor: \n",
    "                pass\n",
    "            else:\n",
    "                motor.append(frame1['stim_loc'][i])\n",
    "        if frame1['error'][i] == 'word':\n",
    "            if frame1['stim_loc'][i] in word: \n",
    "                pass\n",
    "            else:\n",
    "                word.append(frame1['stim_loc'][i])\n",
    "    for x in motor:\n",
    "        if x in word:\n",
    "            if str(x) == 'nan':\n",
    "                pass\n",
    "            else:\n",
    "                comorbid_sites.append(str(x)+'_' + str(p))\n",
    "print(comorbid_sites) \n",
    "print(co_index)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ventral', nan, nan, nan, 'ventral', nan, nan, 'dorsal', nan]\n"
     ]
    }
   ],
   "source": [
    "sites = []\n",
    "for c in co_index:\n",
    "    sites.append(frame1['region'][c])\n",
    "\n",
    "ventral_co = sites.count('ventral') \n",
    "dorsal_co = sites.count('ifg') \n",
    "\n",
    "print(sites)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## counts how many errors are at a given site\n",
    "def count(error,site):\n",
    "    anatomy = pd.DataFrame()\n",
    "    myidx = np.where(frame1['region'] == site)[0]\n",
    "    errors = []\n",
    "    for i in myidx:\n",
    "        errors.append(frame1['error'][i])\n",
    "        errors.append(frame1['error2'][i])\n",
    "    counts = errors.count(error)\n",
    "        \n",
    "    return('number of ' + error + ' errors at site ' + site + ': ' + str(counts))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'number of syllable errors at site other: 0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count('syllable','other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calculating Stim Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/alia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/alia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/alia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/alia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/alia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "framey = frame[frame.stim == 'Y']\n",
    "framey = framey.reindex_axis((\"trial\",\"ptID\", \"s_onset\", \"s_offset\", \"s_dur\", \"stim_onset\", \"stim_offset\", \"during_stim_pos\", \"during_stim_neg\", \"stim_effect\", \"error\",\"error2\", \"during_stim_for_pos\", \"during_stim_for_neg\", \"stim_loc\", \"stim\", \"timePlot\", \"region\"), axis=1)\n",
    "\n",
    "frame1 = pd.DataFrame()\n",
    "for i in framey:\n",
    "    a = framey[i].tolist()\n",
    "    frame1[i] = a\n",
    "\n",
    "frame1['two_before_s_onset'] = 'na'\n",
    "frame1['two_before_s_offset'] = 'na'\n",
    "frame1['one_before_s_offset'] = 'na'\n",
    "frame1['one_before_s_onset'] = 'na'\n",
    "frame1['one_after_s_onset'] = 'na'\n",
    "frame1['one_after_s_offset'] = 'na'\n",
    "\n",
    "for f in range(2,len(frame1['s_onset'])):\n",
    "    frame1['two_before_s_onset'][f] = frame1['s_onset'][f-2]\n",
    "    frame1['two_before_s_offset'][f] = frame1['s_offset'][f-2]\n",
    "    \n",
    "for b in range(1,len(frame1['s_onset'])):\n",
    "    frame1['one_before_s_offset'][b] = frame1['s_offset'][b-1]\n",
    "    frame1['one_before_s_onset'][b] = frame1['s_onset'][b-1]\n",
    "\n",
    "for b in range(0,len(frame1['s_onset'])-1):\n",
    "    frame1['one_after_s_onset'][b] = frame1['s_onset'][b+1]\n",
    "    frame1['one_after_s_offset'][b] = frame1['s_offset'][b+1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# framey['one_after_s_onset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find timing \n",
    "\n",
    "frame1['tbon'] = frame1['two_before_s_onset'][2:].astype(float) - frame1['stim_onset'].astype(float)\n",
    "frame1['tboff'] = frame1['two_before_s_offset'][2:].astype(float) - frame1['stim_onset'].astype(float)\n",
    "\n",
    "frame1['obon'] = frame1['one_before_s_onset'][1:].astype(float) - frame1['stim_onset'].astype(float)\n",
    "frame1['oboff'] = frame1['one_before_s_offset'][1:].astype(float) - frame1['stim_onset'].astype(float)\n",
    "\n",
    "frame1['son'] = frame1['s_onset'].astype(float) - frame1['stim_onset'].astype(float)\n",
    "frame1['soff'] = frame1['s_offset'].astype(float) - frame1['stim_onset'].astype(float)\n",
    "\n",
    "frame1['oaon'] = frame1['one_after_s_onset'][:-1].astype(float) - frame1['stim_onset'].astype(float)\n",
    "frame1['oaoff'] = frame1['one_after_s_offset'][:-1].astype(float) - frame1['stim_offset'].astype(float)\n",
    "\n",
    "\n",
    "frame1['before_gap'] = frame1['obon'] - frame1['tboff']\n",
    "\n",
    "frame1['stim_gap'] = frame1['son'] - frame1['oboff']\n",
    "\n",
    "frame1['after_gap'] = frame1['oaon'] - frame1['soff']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = framey['trial'].tolist()\n",
    "frame1['tiral'] = a\n",
    "frame1 = frame1.reindex_axis(('tiral','ptID', 'before_gap', 'stim_gap', 'after_gap'), axis = 1)\n",
    "frame1.to_csv('stim_info.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
